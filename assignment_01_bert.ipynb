{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b1cfb22-4b03-4682-9a21-bca5cb05c682",
   "metadata": {},
   "source": [
    "# Assignment 1: detecting offensive content on twitter\n",
    "**Assignment due 23 February 11:59pm**\n",
    "\n",
    "Welcome to the first assignment for 50.055 Machine Learning Operations. These assignments give you a chance to practice the methods and tools you have learned. \n",
    "\n",
    "**This assignment is an individual assignment.**\n",
    "\n",
    "- Read the instructions in this notebook carefully\n",
    "- Add your solution code and answers in the appropriate places. The questions are marked as **QUESTION:**, the places where you need to add your code and text answers are marked as **ADD YOUR SOLUTION HERE**\n",
    "- The completed notebook, including your added code and generated output, will be your submission for the assignment.\n",
    "- The notebook should execute without errors from start to finish when you select \"Restart Kernel and Run All Cells..\". Please test this before submission.\n",
    "- Use the SUTD Education Cluster to solve and test the assignment.\n",
    "\n",
    "**Rubric for assessment** \n",
    "\n",
    "Your submission will be graded using the following criteria. \n",
    "1. Code executes: your code should execute without errors. The SUTD Education cluster should be used to ensure the same execution environment.\n",
    "2. Correctness: the code should produce the correct result or the text answer should state the factual correct answer.\n",
    "3. Style: your code should be written in a way that is clean and efficient. Your text answers should be relevant, concise and easy to understand.\n",
    "4. Partial marks will be awarded for partially correct solutions.\n",
    "5. There is a maximum of 76 points for this assignment.\n",
    "\n",
    "\n",
    "**ChatGPT policy:** \n",
    "\n",
    "If you use AI tools, such as ChatGPT, to solve the assignment questions, you need to be transparent about its use and mark AI-generated content as such. In particular, you should include the following in addition to your final answer:\n",
    "- A copy or screenshot of the prompt you used\n",
    "- The name of the AI model\n",
    "- The AI generated output\n",
    "- An explanation why the answer is correct or what you had to change to arrive at the correct answer\n",
    "\n",
    "**Assignment Notes:** Please make sure to save the notebook as you go along. Submission Instructions are located at the bottom of the notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "980439b6-d91e-467e-a0b8-45a0d6637c45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers[torch] in c:\\users\\wintk\\anaconda3\\lib\\site-packages (4.37.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from transformers[torch]) (0.4.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from transformers[torch]) (2022.3.15)\n",
      "Requirement already satisfied: filelock in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from transformers[torch]) (3.6.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from transformers[torch]) (0.15.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from transformers[torch]) (21.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from transformers[torch]) (4.64.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from transformers[torch]) (1.26.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from transformers[torch]) (6.0)\n",
      "Requirement already satisfied: requests in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from transformers[torch]) (2.27.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from transformers[torch]) (0.20.3)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from transformers[torch]) (0.27.2)\n",
      "Requirement already satisfied: torch!=1.12.0,>=1.11 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from transformers[torch]) (2.1.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from accelerate>=0.21.0->transformers[torch]) (5.8.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (4.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers[torch]) (3.0.4)\n",
      "Requirement already satisfied: networkx in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from torch!=1.12.0,>=1.11->transformers[torch]) (2.7.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from torch!=1.12.0,>=1.11->transformers[torch]) (2.11.3)\n",
      "Requirement already satisfied: sympy in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from torch!=1.12.0,>=1.11->transformers[torch]) (1.10.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers[torch]) (0.4.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from jinja2->torch!=1.12.0,>=1.11->transformers[torch]) (2.0.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from requests->transformers[torch]) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from requests->transformers[torch]) (1.26.18)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from requests->transformers[torch]) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from requests->transformers[torch]) (2.0.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from sympy->torch!=1.12.0,>=1.11->transformers[torch]) (1.2.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\wintk\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\wintk\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\wintk\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\wintk\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\wintk\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\wintk\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\wintk\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\wintk\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\wintk\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\wintk\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\wintk\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\wintk\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: evaluate in c:\\users\\wintk\\anaconda3\\lib\\site-packages (0.4.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from evaluate) (0.20.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from evaluate) (21.3)\n",
      "Requirement already satisfied: datasets>=2.0.0 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from evaluate) (2.17.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from evaluate) (2.27.1)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from evaluate) (1.26.2)\n",
      "Requirement already satisfied: dill in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from evaluate) (4.64.0)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from evaluate) (2023.10.0)\n",
      "Requirement already satisfied: responses<0.19 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from evaluate) (0.18.0)\n",
      "Requirement already satisfied: xxhash in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from evaluate) (3.4.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from evaluate) (1.4.2)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from datasets>=2.0.0->evaluate) (15.0.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from datasets>=2.0.0->evaluate) (3.6.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from datasets>=2.0.0->evaluate) (3.8.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from datasets>=2.0.0->evaluate) (6.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from datasets>=2.0.0->evaluate) (0.6)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (5.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.6.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.2.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.2.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (21.4.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.0.4)\n",
      "Requirement already satisfied: typing-extensions>=3.6.5 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from async-timeout<5.0,>=4.0.0a3->aiohttp->datasets>=2.0.0->evaluate) (4.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from packaging->evaluate) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from requests>=2.19.0->evaluate) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from requests>=2.19.0->evaluate) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from requests>=2.19.0->evaluate) (1.26.18)\n",
      "Requirement already satisfied: colorama in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from tqdm>=4.62.1->evaluate) (0.4.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from pandas->evaluate) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\wintk\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\wintk\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\wintk\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\wintk\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\wintk\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\wintk\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\wintk\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\wintk\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\wintk\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\wintk\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\wintk\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\wintk\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\wintk\\anaconda3\\lib\\site-packages (1.0.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: numpy>=1.14.6 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from scikit-learn) (1.26.2)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from scikit-learn) (1.11.4)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from scikit-learn) (1.1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\wintk\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\wintk\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\wintk\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\wintk\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\wintk\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\wintk\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\wintk\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\wintk\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\wintk\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\wintk\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\wintk\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\wintk\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in c:\\users\\wintk\\anaconda3\\lib\\site-packages (2.17.1)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from datasets) (15.0.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from datasets) (1.26.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from datasets) (2.27.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from datasets) (0.20.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from datasets) (21.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from datasets) (4.64.0)\n",
      "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from datasets) (2023.10.0)\n",
      "Requirement already satisfied: xxhash in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: pyarrow-hotfix in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: pandas in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from datasets) (1.4.2)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from datasets) (3.8.1)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (2.0.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.6.3)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (4.0.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (5.1.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (21.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.5 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from async-timeout<5.0,>=4.0.0a3->aiohttp->datasets) (4.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from packaging->datasets) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (1.26.18)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (2021.10.8)\n",
      "Requirement already satisfied: colorama in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from tqdm>=4.62.1->datasets) (0.4.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from pandas->datasets) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\wintk\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\wintk\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\wintk\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\wintk\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\wintk\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\wintk\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\wintk\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\wintk\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\wintk\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\wintk\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\wintk\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\wintk\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wandb in c:\\users\\wintk\\anaconda3\\lib\\site-packages (0.16.3)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.1 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from wandb) (8.0.4)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from wandb) (6.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from wandb) (4.1.1)\n",
      "Requirement already satisfied: appdirs>=1.4.3 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from wandb) (1.4.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from wandb) (67.6.0)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from wandb) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from wandb) (2.27.1)\n",
      "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from wandb) (3.1.42)\n",
      "Requirement already satisfied: setproctitle in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from wandb) (1.3.3)\n",
      "Requirement already satisfied: psutil>=5.0.0 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from wandb) (5.8.0)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from wandb) (1.40.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from Click!=8.0.0,>=7.1->wandb) (0.4.4)\n",
      "Requirement already satisfied: six>=1.4.0 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (1.26.18)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\wintk\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\wintk\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\wintk\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\wintk\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\wintk\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\wintk\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\wintk\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\wintk\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\wintk\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\wintk\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\wintk\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\wintk\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in c:\\users\\wintk\\anaconda3\\lib\\site-packages (0.13.0)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from seaborn) (1.4.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from seaborn) (1.26.2)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.3 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from seaborn) (3.5.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (3.0.4)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (4.25.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (9.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (1.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (21.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from pandas>=1.2->seaborn) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\wintk\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.3->seaborn) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\wintk\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\wintk\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\wintk\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\wintk\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\wintk\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\wintk\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\wintk\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\wintk\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\wintk\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\wintk\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\wintk\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\wintk\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "# Installing all required packages\n",
    "# Note: Do not add to this list.\n",
    "# ----------------\n",
    "! pip install transformers[torch]\n",
    "! pip install evaluate\n",
    "! pip install scikit-learn\n",
    "! pip install datasets\n",
    "! pip install wandb\n",
    "! pip install seaborn \n",
    "# ----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a272f7c4-8dec-4ec8-986c-2ee28ed366f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\wintk\\anaconda3\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Importing all required packages\n",
    "# ----------------\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import evaluate\n",
    "import time\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import transformers\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from datasets import load_dataset\n",
    "# ----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adda5aa5-1297-4767-b36e-05fe6df2cb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f84068-a112-46a0-b531-494a903eccae",
   "metadata": {},
   "source": [
    "# Offensive language detection\n",
    "\n",
    "Content moderation of offensive or hateful language is an important task on social media platforms. \n",
    "In this assignment, you will train a text classification models for detecting offensive language on twitter. You will run experiments with different models and evaluate their performance and costs.\n",
    "\n",
    "We will use the TweetEval data set from Barbiert et al (2020): https://aclanthology.org/2020.findings-emnlp.148.pdf\n",
    "\n",
    "\n",
    "**Warning**\n",
    "Some of the content contains rude and offensive language. If you know that this causes you distress, let the course instructor know to arrange a different assessment.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "730b9f1f-5862-40c0-8b10-a1b7c23fac90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 11916\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 860\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 1324\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data set \n",
    "dataset = load_dataset(\"tweet_eval\", \"offensive\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e89a6973-1615-4d7d-8751-744e140465ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': '@user Bono... who cares. Soon people will understand that they gain nothing from following a phony celebrity. Become a Leader of your people instead or help and support your fellow countrymen.', 'label': 0}\n"
     ]
    }
   ],
   "source": [
    "# QUESTION: print the first training set sample \n",
    "\n",
    "#--- ADD YOUR SOLUTION HERE (1 point)---\n",
    "print(dataset[\"train\"][0])\n",
    "\n",
    "#------------------------------\n",
    "# Hint: you should see a tweet about U2 singer Bono"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f8915fe-1ed9-4b4a-82ed-fa34de18427f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label values: [0 1]\n",
      "ClassLabel(names=['non-offensive', 'offensive'], id=None)\n"
     ]
    }
   ],
   "source": [
    "# QUESTION: what are the possible values of the labels? What is their meaning? \n",
    "# Print the set of label values and their label names\n",
    "#--- ADD YOUR SOLUTION HERE (5 points) ---\n",
    "unique_labels = np.unique(dataset['train']['label'])\n",
    "print(f'Label values: {unique_labels}')\n",
    "print(dataset[\"train\"].features['label'])\n",
    "\n",
    "# -------\n",
    "# Hint: it is a binary task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fdbf3671-1066-4458-92fd-dc1932094187",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# QUESTION: plot a bar chart of the label distribution\n",
    "#--- ADD YOUR SOLUTION HERE (5 points) ---\n",
    "sns.countplot(x='label', data=pd.DataFrame(dataset['train']))\n",
    "plt.show()\n",
    "\n",
    "#------------------------------\n",
    "# Hint: it is not evenly distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f73f29c-9728-4a19-8d5a-9e7440d56f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QUESTION: separate data set into training, validation and test according to given dataset split\n",
    "# You should end up with the following variables\n",
    "# train_text = array containing strings in training set\n",
    "# train_labels = array containing numeric labels in training set\n",
    "# validation_text = array containing strings in training set\n",
    "# validation_labels = array containing numeric labels in training set\n",
    "# test_text = array containing strings in training set\n",
    "# test_labels = array containing numeric labels in training set\n",
    "\n",
    "#--- ADD YOUR SOLUTION HERE (10 points) ---\n",
    "train_text = dataset['train']['text']\n",
    "train_labels = dataset['train']['label']\n",
    "\n",
    "validation_text = dataset['validation']['text']\n",
    "validation_labels = dataset['validation']['label']\n",
    "\n",
    "test_text = dataset['test']['text']\n",
    "test_labels = dataset['test']['label']\n",
    "\n",
    "#------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4254bcf4-3926-4989-99a4-6985e3410caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#train:  11916\n",
      "#validation:  1324\n",
      "#test:  860\n"
     ]
    }
   ],
   "source": [
    "# check the size of the data splits\n",
    "print(\"#train: \", len(train_text)) \n",
    "print(\"#validation: \", len(validation_text)) \n",
    "print(\"#test: \", len(test_text)) \n",
    "\n",
    "# Hint: you should see\n",
    "#train:  11916\n",
    "#validation:  1324\n",
    "#test:  860"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9562c182-b658-49b3-bcd3-852052dc7e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# QUESTION: create a scikit-learn pipeline object that creates unigram features, applies tf-idf weighting and trains a SGDClassifier \n",
    "# tf-idf stands for “Term Frequency times Inverse Document Frequency”.\n",
    "# tf-idf is a feature weighting methods commonly used in NLP and IR\n",
    "# use default parameters for unigram feature extraction, tf-idf and the SGDClassifier\n",
    "# add additional import statements in this cell as needed\n",
    "\n",
    "#--- ADD YOUR SOLUTION HERE (10 points) ---\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', SGDClassifier())\n",
    "])\n",
    "\n",
    "# Now the pipeline is ready for making predictions on new data.\n",
    "# You can use it like this:\n",
    "# predictions = pipeline.predict(new_data)\n",
    "\n",
    "\n",
    "#------------------------------\n",
    "# Hint: use the scikit-learn library"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f27bb73-f483-4364-9b9a-59493031cfcf",
   "metadata": {},
   "source": [
    "# Train the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54deb077-2ede-425c-91f8-32d24381f4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# QUESTION: apply your pipeline of feature extraction and model training to the training set\n",
    "# Measure the wall-clock training time needed \n",
    "# Store the training time in a variable 'train_time_sgd\n",
    "#--- ADD YOUR SOLUTION HERE (5 points) ---\n",
    "start_time = time.time()\n",
    "pipeline.fit(train_text, train_labels)\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate the training time\n",
    "train_time_sgd = end_time - start_time\n",
    "\n",
    "#------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3de2987f-83f1-4948-a390-05ed2517f151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0.3909461498260498s\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training time: {train_time_sgd}s\")\n",
    "\n",
    "# Hint: training should take < 1 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0637838e-9741-4c6f-a889-e76dfbe25ead",
   "metadata": {},
   "source": [
    "# Test the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f2c2a4a7-78ea-4942-afe3-cf20d177eca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation precision: 0.4268312857677458\n",
      "Validation recall: 0.6533232628398792\n",
      "Validation F1: 0.5163313132539932\n",
      "---\n",
      "Test precision: 0.519740400216333\n",
      "Test recall: 0.7209302325581395\n",
      "Test F1: 0.6040226272784412\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "# QUESTION: compute the majority class baseline score on the validation set and test set\n",
    "# the majority class baseline is the score you get if you always predict the most frequent label\n",
    "# \n",
    "# Compute the precision, recall and F1 score for the majority baseline for validation and test set for each class\n",
    "#\n",
    "#--- ADD YOUR SOLUTION HERE (5 points) ---\n",
    "majority_class_val = [0 for label in validation_labels]\n",
    "majority_class_test = [0 for label in test_labels]\n",
    "\n",
    "def compute_majority_baseline_metrics(y_true_labels, majority_pred_labels):\n",
    "    \n",
    "    precision = metrics.precision_score(y_true_labels, majority_pred_labels, average = 'weighted', zero_division = 0)\n",
    "    recall = metrics.recall_score(y_true_labels, majority_pred_labels, average = 'weighted', zero_division = 0)\n",
    "    f1 = metrics.f1_score(y_true_labels, majority_pred_labels, average = 'weighted', zero_division = 0)\n",
    "    \n",
    "    return precision, recall, f1\n",
    "\n",
    "val_precision, val_recall, val_f1 = compute_majority_baseline_metrics(validation_labels, majority_class_val)\n",
    "test_precision, test_recall, test_f1 = compute_majority_baseline_metrics(test_labels, majority_class_test)\n",
    "\n",
    "print(f'Validation precision: {val_precision}')\n",
    "print(f'Validation recall: {val_recall}')\n",
    "print(f'Validation F1: {val_f1}')\n",
    "print('---')\n",
    "print(f'Test precision: {test_precision}')\n",
    "print(f'Test recall: {test_recall}')\n",
    "print(f'Test F1: {test_f1}')\n",
    "\n",
    "#------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c1a2cb65-1d21-4df8-b339-adc157eef182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.7628398791540786\n",
      "Validation precision: 0.8310502283105022\n",
      "Validation recall: 0.39651416122004357\n",
      "Validation F1: 0.5368731563421829\n",
      "---\n",
      "Test accuracy: 0.8058139534883721\n",
      "Test precision: 0.8288288288288288\n",
      "Test recall: 0.38333333333333336\n",
      "Test F1: 0.5242165242165243\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "# \n",
    "# QUESTION: now use your pipeline to make predictions on validation and test set\n",
    "# compute and print accuracy, precision, recall, F1 score\n",
    "# \n",
    "# From now on, we are only concerned with the F1 score for the \"positive\" class which are the offensive tweets\n",
    "# Store the test F1 score for the \"positive\" class in a variable 'f1_validation_sgd' and 'f1_test_sgd' for validation and test set, respectively \n",
    "#--- ADD YOUR SOLUTION HERE (10 points) ---\n",
    "val_pred = pipeline.predict(validation_text)\n",
    "test_pred = pipeline.predict(test_text)\n",
    "\n",
    "def compute_sgd_metrics(y_true, y_pred):\n",
    "    \n",
    "    accuracy = metrics.accuracy_score(y_true, y_pred)\n",
    "    precision = metrics.precision_score(y_true, y_pred, pos_label=1, average='binary')\n",
    "    recall = metrics.recall_score(y_true, y_pred, pos_label=1, average='binary')\n",
    "    f1 = metrics.f1_score(y_true, y_pred, pos_label=1, average='binary')\n",
    "    \n",
    "    return accuracy, precision, recall, f1\n",
    "    \n",
    "accuracy_validation_sgd, precision_validation_sgd, \\\n",
    "recall_validation_sgd, f1_validation_sgd = compute_sgd_metrics(validation_labels, val_pred)\n",
    "\n",
    "accuracy_test_sgd, precision_test_sgd, \\\n",
    "recall_test_sgd, f1_test_sgd = compute_sgd_metrics(test_labels, test_pred)\n",
    "\n",
    "print(f'Validation accuracy: {accuracy_validation_sgd}')\n",
    "print(f'Validation precision: {precision_validation_sgd}')\n",
    "print(f'Validation recall: {recall_validation_sgd}')\n",
    "print(f'Validation F1: {f1_validation_sgd}')\n",
    "print('---')\n",
    "print(f'Test accuracy: {accuracy_test_sgd}')\n",
    "print(f'Test precision: {precision_test_sgd}')\n",
    "print(f'Test recall: {recall_test_sgd}')\n",
    "print(f'Test F1: {f1_test_sgd}')\n",
    "\n",
    "#------------------------------\n",
    "# Hint: F1 scores should be >50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6421fa9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.8489425981873112\n",
      "Train precision: 0.9311316955296013\n",
      "Train recall: 0.5866531337224055\n",
      "Train F1: 0.7198007471980075\n"
     ]
    }
   ],
   "source": [
    "train_pred = pipeline.predict(train_text)\n",
    "accuracy_train_sgd, precision_train_sgd, \\\n",
    "recall_train_sgd, f1_train_sgd = compute_sgd_metrics(train_labels, train_pred)\n",
    "\n",
    "print(f'Train accuracy: {accuracy_train_sgd}')\n",
    "print(f'Train precision: {precision_train_sgd}')\n",
    "print(f'Train recall: {recall_train_sgd}')\n",
    "print(f'Train F1: {f1_train_sgd}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7958c9e-6aab-4066-a0f0-0296e08c0935",
   "metadata": {},
   "source": [
    "# BERT model\n",
    "\n",
    "Now let us try a more powerful model: the DistilBERT uncased model\n",
    "\n",
    "https://huggingface.co/distilbert-base-uncased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4106f683-1c93-414f-b7ba-31a3722367da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1324/1324 [00:00<00:00, 3163.63 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# load DistilBERT tokenizer and tokenize data set\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "train_dataset = tokenized_datasets[\"train\"]\n",
    "eval_dataset = tokenized_datasets[\"validation\"]\n",
    "test_dataset = tokenized_datasets[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "09087fb6-1cc6-457c-b601-316d7bb3b3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# load DistilBERT model for classification\n",
    "\n",
    "#--- ADD YOUR SOLUTION HERE (5 points) ---\n",
    "model = transformers.AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "\n",
    "#------------------------------\n",
    "# Hint: make sure your model corresponds to your tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0d865dca-a413-4060-ac4e-a49039262f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add custom metrics that computes precision, recall, f1, accuracy\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "\n",
    "   # Calculate precision, recall, and F1-score\n",
    "    precision = precision_score(labels, preds, average='binary')\n",
    "    recall = recall_score(labels, preds, average='binary')\n",
    "    f1 = f1_score(labels, preds, average='binary')\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "edcbf727-1479-4b81-988a-c18eba4de126",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#\n",
    "# QUESTION: configure the training parameters using the Huggingface TrainingArguments class\n",
    "# - set the output directory to \"finetuning-tweeteval\"\n",
    "# - do not report training metrics to an external experiment tracking service\n",
    "# - print acc/p/r/f1 scores on the validation set every 200 steps\n",
    "# - learning rate to 2e-5, \n",
    "# - set weight decay to 0.01\n",
    "# - set epochs to 1\n",
    "\n",
    "\n",
    "#--- ADD YOUR SOLUTION HERE (5 points) ---\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    logging_steps = 200,\n",
    "    output_dir = 'finetuning-tweeteval',\n",
    "    evaluation_strategy = 'steps',\n",
    "    eval_steps = 200,\n",
    "    learning_rate = 2e-5,\n",
    "    weight_decay = 0.01,\n",
    "    num_train_epochs = 1,\n",
    "    report_to = None\n",
    ")\n",
    "\n",
    "#------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "52ef1bb5-565d-4d9d-ad4a-cfba3f6d47d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "30d891ae-4a62-44d1-8cf1-d05a1bc75074",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mwintkyaw\u001b[0m (\u001b[33manchar\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/sutd-mlops-course-code/wandb/run-20240222_052129-02jrs3ez</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/anchar/huggingface/runs/02jrs3ez' target=\"_blank\">auspicious-rocket-4</a></strong> to <a href='https://wandb.ai/anchar/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/anchar/huggingface' target=\"_blank\">https://wandb.ai/anchar/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/anchar/huggingface/runs/02jrs3ez' target=\"_blank\">https://wandb.ai/anchar/huggingface/runs/02jrs3ez</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1490' max='1490' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1490/1490 04:14, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.567300</td>\n",
       "      <td>0.531740</td>\n",
       "      <td>0.738671</td>\n",
       "      <td>0.592471</td>\n",
       "      <td>0.788671</td>\n",
       "      <td>0.676636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.505100</td>\n",
       "      <td>0.449356</td>\n",
       "      <td>0.794562</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.599129</td>\n",
       "      <td>0.669100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.468900</td>\n",
       "      <td>0.456204</td>\n",
       "      <td>0.790785</td>\n",
       "      <td>0.724138</td>\n",
       "      <td>0.640523</td>\n",
       "      <td>0.679769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.435100</td>\n",
       "      <td>0.465956</td>\n",
       "      <td>0.789275</td>\n",
       "      <td>0.735602</td>\n",
       "      <td>0.612200</td>\n",
       "      <td>0.668252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.457600</td>\n",
       "      <td>0.440276</td>\n",
       "      <td>0.792296</td>\n",
       "      <td>0.756983</td>\n",
       "      <td>0.590414</td>\n",
       "      <td>0.663403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.451100</td>\n",
       "      <td>0.435188</td>\n",
       "      <td>0.799849</td>\n",
       "      <td>0.765027</td>\n",
       "      <td>0.610022</td>\n",
       "      <td>0.678788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.442500</td>\n",
       "      <td>0.431384</td>\n",
       "      <td>0.799094</td>\n",
       "      <td>0.730310</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.697039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory finetuning-tweeteval/checkpoint-500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory finetuning-tweeteval/checkpoint-1000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "start_time = time.time()\n",
    "train_output = trainer.train()\n",
    "end_time = time.time()\n",
    "train_time_bert = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "003379b3-a5ba-4d80-8998-514d57bf2449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1764' max='1490' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1490/1490 01:16]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.3673073649406433,\n",
       " 'eval_accuracy': 0.8449983215844243,\n",
       " 'eval_precision': 0.7771307570142932,\n",
       " 'eval_recall': 0.7449885815782796,\n",
       " 'eval_f1': 0.760720300557067,\n",
       " 'eval_runtime': 64.4447,\n",
       " 'eval_samples_per_second': 184.903,\n",
       " 'eval_steps_per_second': 23.121,\n",
       " 'epoch': 1.0}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate on training set\n",
    "trainer.evaluate(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6eeb0514-431e-44b0-8372-c57e354bc330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.4329206943511963,\n",
       " 'eval_accuracy': 0.7983383685800605,\n",
       " 'eval_precision': 0.7152466367713004,\n",
       " 'eval_recall': 0.6949891067538126,\n",
       " 'eval_f1': 0.7049723756906078,\n",
       " 'eval_runtime': 7.2743,\n",
       " 'eval_samples_per_second': 182.011,\n",
       " 'eval_steps_per_second': 22.82,\n",
       " 'epoch': 1.0}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate on validation set\n",
    "trainer.evaluate(eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c51d1460-504c-4ab3-8eaf-0691f1f5a91f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3756254315376282, 'eval_accuracy': 0.8348837209302326, 'eval_precision': 0.7311320754716981, 'eval_recall': 0.6458333333333334, 'eval_f1': 0.6858407079646017, 'eval_runtime': 4.7432, 'eval_samples_per_second': 181.311, 'eval_steps_per_second': 22.769, 'epoch': 1.0}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test set\n",
    "test_output = trainer.evaluate(test_dataset)\n",
    "print(test_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1d39da-72df-410e-adb4-325c6be590d4",
   "metadata": {},
   "source": [
    "### QUESTION: \n",
    "Do you see any signs of overfitting or underfitting based on the evaluation scores\n",
    "Explain why or why not\n",
    "\n",
    "**--- ADD YOUR SOLUTION HERE (5 points) ---**\n",
    "\n",
    "As the accuracy, precision, recall and f1 scores of the model on the validation and test sets are reasonably high when consdering the difficulty of the task, the model is not underfitting. At the same time, there is not a significant decrease in overall performance of the model when moving from the training set to the validation and test sets. Hence, the model is only slightly overfitting.\n",
    "\n",
    "------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c82913fe-0bbc-41de-acae-ad0662926b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD Ratio: 1.3507995612066297\n",
      "BERT Ratio: 0.0026141973173371994\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# QUESTION: What is the ratio f1 score to training time for the SGDClassifier and the DistilBERT model\n",
    "# compute the two ratios and print them\n",
    "\n",
    "#--- ADD YOUR SOLUTION HERE ---\n",
    "\n",
    "ratio_sgd = f1_test_sgd/train_time_sgd\n",
    "ratio_bert = test_output['eval_f1']/train_time_bert\n",
    "\n",
    "print(f'SGD Ratio: {ratio_sgd}')\n",
    "print(f'BERT Ratio: {ratio_bert}')\n",
    "\n",
    "#------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4e7d14-f997-4022-ab46-2cb1ac247073",
   "metadata": {},
   "source": [
    "### QUESTION: \n",
    "Given the results what model would you recommend to use? Write a paragraph (max 200 words) to explain your choice\n",
    "\n",
    "**--- ADD YOUR SOLUTION HERE (10 points)---**\n",
    "\n",
    "I would recommend the DistilBERT uncased model despite the drastically lower f1 score to training time ratio. While the SGD classifier had a higher test precision of 0.829 than the baseline of 0.520, it had a significantly lower recall of 0.383 compared to 0.721, as well as a lower F1 score of 0.524 compared to 0.604. Additionally, it seems to be overfitting as the training F1 score was significantly higher at 0.720. Meanwhile, the DistilBERT uncased model had better test performance than the baseline in all metrics except recall, in which it only slightly lost out at 0.646. Furthermore, it is not overfitting severely. Detecting offensive content is also a somewhat challenging task that requires a deeper understanding of language, such as context and semiotics, than simply decomposing sentences into unigrams and computing the tf-idf scores. Hence, a model that uses language embeddings, such as DistilBERT uncased, would be more suitable for this task.\n",
    "\n",
    "------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc57acf-c65a-4ba7-9d9c-9b212251e542",
   "metadata": {},
   "source": [
    "# End\n",
    "\n",
    "This concludes assignment 1.\n",
    "\n",
    "\n",
    "Please submit this notebook with your answers and the generated output cells as a **Jupyter notebook file** (assignment_01_STUDENT_NAME.ipynb) and the **text file reddit_labeled__STUDENT_NAME.csv** via the eDimensions tool, where STUDENT_NAME is your name in your SUTD email address.\n",
    "\n",
    "Example:\n",
    "Email: michael_tan@mymail.sutd.edu.sg\n",
    "STUDENT_NAME: michael_tan\n",
    "Submission file name: assignment_03_michael_tan.ipynb\n",
    "\n",
    "**Assignment due 23 February 11:59pm**\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
